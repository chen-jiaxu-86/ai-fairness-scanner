import pandas as pd
import numpy as np
from fairlearn.metrics import (
    demographic_parity_difference,
    equalized_odds_difference,
    MetricFrame,
    selection_rate,
    count
)
from fairlearn.reductions import GridSearch, DemographicParity
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score
import streamlit as st
import warnings

warnings.filterwarnings("ignore")


def load_data(file_path, file_type='csv'):
    try:
        if file_type.lower() == 'csv':
            df = pd.read_csv(file_path)
        elif file_type.lower() == 'excel':
            df = pd.read_excel(file_path)
        else:
            raise ValueError("æ–‡ä»¶ç±»å‹å¿…é¡»æ˜¯'excel'æˆ–â€˜csv'")
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å½¢çŠ¶: {df.shape}")
        print(f"ğŸ“Š æ•°æ®åˆ—: {list(df.columns)}")
        print("\nğŸ” æ•°æ®å‰5è¡Œ:")
        print(df.head())
        print("\nğŸ“‹ æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(df.info())

        return df
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None


def data_preprocessing(df, features, sensitive_feature, target_column):
    try:
        print("=== é¢„å¤„ç†å‡½æ•°å†…éƒ¨å¼€å§‹ ===")
        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {df.shape}")

        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = features + [sensitive_feature, target_column]
        print(f"éœ€è¦çš„åˆ—: {required_columns}")

        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            print(f"é”™è¯¯: ä»¥ä¸‹åˆ—ä¸å­˜åœ¨: {missing_columns}")
            print(f"æ•°æ®æ¡†ä¸­å®é™…å­˜åœ¨çš„åˆ—: {list(df.columns)}")
            return None, None

        print("æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨")

        # æ£€æŸ¥ç¼ºå¤±å€¼
        print("ç¼ºå¤±å€¼ç»Ÿè®¡:")
        missing_stats = df[required_columns].isnull().sum()
        print(missing_stats)

        # å¤„ç†ç¼ºå¤±å€¼ - åˆ é™¤æœ‰ç¼ºå¤±å€¼çš„è¡Œ
        df_clean = df[required_columns].copy()
        initial_count = len(df_clean)
        df_clean = df_clean.dropna()
        final_count = len(df_clean)

        print(f"æ•°æ®æ¸…ç†: {initial_count} -> {final_count} è¡Œ")

        # ç¡®ä¿è¿˜æœ‰æ•°æ®
        if len(df_clean) == 0:
            print("è­¦å‘Š: æ¸…ç†åæ²¡æœ‰æ•°æ®äº†")
            return None, None

        print("é¢„å¤„ç†å®Œæˆ!")
        print(f"è¿”å›æ•°æ®å½¢çŠ¶: {df_clean.shape}")
        return df_clean, features

    except Exception as e:
        print(f"é¢„å¤„ç†å‡½æ•°å†…éƒ¨é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None, None


print("ğŸ¯ æ£€æŸ¥ç‚¹ï¼šdata_preprocessingè°ƒç”¨å®Œæˆ")


def fairlearn_analysis(df, sensitive_feature, target_column, features):
    X = df[features]
    y = df[target_column]
    A = df[sensitive_feature]

    # å°† Xã€yã€A æŒ‰åˆ—ç»„åˆï¼Œç„¶åè¿›è¡Œåˆ†å‰²
    combined = pd.concat([X, y, A], axis=1)
    train, test = train_test_split(combined, test_size=0.3, random_state=42, stratify=y)
    X_train = train[features]
    X_test = test[features]
    y_train = train[target_column]
    y_test = test[target_column]
    A_train = train[sensitive_feature]
    A_test = test[sensitive_feature]

    print(f"\nğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    print(f"æ•æ„Ÿç‰¹å¾åˆ†å¸ƒ:\n{A_test.value_counts()}")
    # è®­ç»ƒåŸºç¡€æ¨¡å‹
    print("\nğŸ¤– è®­ç»ƒåŸºç¡€æ¨¡å‹...")
    base_model = RandomForestClassifier(n_estimators=100, random_state=42)
    base_model.fit(X_train, y_train)
    y_pred_base = base_model.predict(X_test)

    print("\n" + "=" * 60)
    print("ğŸ“Š FAIRLEARN å…¬å¹³æ€§åˆ†ææŠ¥å‘Š")
    print("=" * 60)

    # åŸºç¡€æ¨¡å‹æ€§èƒ½
    base_accuracy = accuracy_score(y_test, y_pred_base)
    base_precision = precision_score(y_test, y_pred_base, average='weighted')
    base_recall = recall_score(y_test, y_pred_base, average='weighted')

    print(f"\nğŸ¯ åŸºç¡€æ¨¡å‹æ€§èƒ½:")
    print(f"å‡†ç¡®ç‡: {base_accuracy:.3f}")
    print(f"ç²¾ç¡®ç‡: {base_precision:.3f}")
    print(f"å¬å›ç‡: {base_recall:.3f}")
    # åŸºç¡€æ¨¡å‹æ€§èƒ½
    dp_diff = demographic_parity_difference(y_test, y_pred_base, sensitive_features=A_test)
    eo_diff = equalized_odds_difference(y_test, y_pred_base, sensitive_features=A_test)

    print(f"\nâš–ï¸ å…¬å¹³æ€§æŒ‡æ ‡:")
    print(f"ç»Ÿè®¡å‡ç­‰å·®å¼‚: {dp_diff:.3f} (è¶Šæ¥è¿‘0è¶Šå…¬å¹³)")
    print(f"å‡ç­‰å‡ ç‡å·®å¼‚: {eo_diff:.3f} (è¶Šæ¥è¿‘0è¶Šå…¬å¹³)")

    metrics = {
        'accuracy': accuracy_score,
        'precision': lambda y_true, y_pred: precision_score(y_true, y_pred, average='binary'),
        'recall': lambda y_true, y_pred: recall_score(y_true, y_pred, average='binary'),
        'selection_rate': selection_rate,
        'count': count,
    }

    metric_frame = MetricFrame(
        metrics=metrics,
        y_true=y_test,
        y_pred=y_pred_base,
        sensitive_features=A_test,
    )

    print(f"\nğŸ“‹ æŒ‰ [{sensitive_feature}] åˆ†ç»„çš„è¯¦ç»†æŒ‡æ ‡:")
    print(metric_frame.by_group.round(3))

    # åå·®åˆ†æ
    print(f"\nğŸ“ˆ åå·®åˆ†æ:")
    overall_selection_rate = metric_frame.overall['selection_rate']
    group_selection_rate = metric_frame.by_group['selection_rate']

    for group, rate in group_selection_rate.items():
        bias = rate - overall_selection_rate
        print(f"  {group}: é€‰æ‹©ç‡ = {rate:.3f}, åå·® = {bias:+.3f}")

    return {
        'model': base_model,
        'X_test': X_test,
        'y_test': y_test,
        'A_test': A_test,
        'y_pred_base': y_pred_base,
        'metrics': metric_frame,
        'fairness_metrics': {
            'demographic_parity_diff': dp_diff,
            'equalized_odds_diff': eo_diff,
        }
    }


if __name__ == '__main__':
    print("âš ï¸  æ³¨æ„ï¼šå½“å‰æ¨¡å¼å°†è®­ç»ƒä¸€ä¸ªæ–°çš„éšæœºæ£®æ—æ¨¡å‹ç”¨äºæ¼”ç¤º")
    print("ğŸ“Š å®é™…ä¸šåŠ¡ä¸­è¯·ä½¿ç”¨ 'æ¨¡å‹è¯„ä¼°' æ¨¡å¼")
    print("AIå®‰å…¨æ€§åˆ†æå·¥å…·")
    print("1.åŠ è½½æ•°æ®æ–‡ä»¶")

    file_path = "fairlearn_data.csv"  # æˆ– .xlsx
    file_type = "csv"  # æˆ– "excel"

    features = ['age', 'income', 'credit_score','employment_years', 'debt_to_income']
    df = load_data(file_path, file_type)


    # åœ¨ä¸»ç¨‹åºä¸­æ·»åŠ æ›´è¯¦ç»†çš„è°ƒè¯•
    print("=== è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")

    print("=== è°ƒç”¨å‰çš„å˜é‡æ£€æŸ¥ ===")
    print(f"df ç±»å‹: {type(df)}")
    print(f"df å½¢çŠ¶: {df.shape}")
    print(f"features å€¼: {features}")
    print(f"features ç±»å‹: {type(features)}")

    # æ£€æŸ¥ features æ˜¯å¦æ­£å¸¸
    if not isinstance(features, list) or features != ['age', 'income', 'credit_score', 'employment_years',
                                                      'debt_to_income']:
        print("âš ï¸ è­¦å‘Š: features å˜é‡å¼‚å¸¸ï¼Œé‡æ–°å®šä¹‰!")
        features = ['age', 'income', 'credit_score', 'employment_years', 'debt_to_income']
        print(f"é‡æ–°å®šä¹‰åçš„ features: {features}")

    print(f"sensitive_feature: {'gender'}")
    print(f"target_column: {'loan_approved'}")

    # 1. æ£€æŸ¥é¢„å¤„ç†å‡½æ•°è°ƒç”¨
    print("1. è°ƒç”¨é¢„å¤„ç†å‡½æ•°...")
    df_clean, features_clean = data_preprocessing(
        df,
        features=['age', 'income', 'credit_score', 'employment_years', 'debt_to_income'],
        sensitive_feature='gender',
        target_column='loan_approved'
    )

    print("2. é¢„å¤„ç†å‡½æ•°è¿”å›ç»“æœ:")
    print(f"df_clean ç±»å‹: {type(df_clean)}")
    print(f"df_clean æ˜¯å¦ä¸º None: {df_clean is None}")
    print(f"features_clean: {features_clean}")

    if df_clean is not None:
        print(f"df_clean å½¢çŠ¶: {df_clean.shape}")
        print(f"df_clean åˆ—å: {df_clean.columns.tolist()}")
        print("é¢„å¤„ç†åçš„æ•°æ®æ ·æœ¬:")
        print(df_clean.head())
    else:
        print("é¢„å¤„ç†è¿”å›äº† Noneï¼Œæ£€æŸ¥é¢„å¤„ç†å‡½æ•°å†…éƒ¨")
        exit()

    # 3. æ£€æŸ¥ fairlearn_analysis å‡½æ•°è°ƒç”¨
    print("\n3. å‡†å¤‡è°ƒç”¨å…¬å¹³æ€§åˆ†æ...")
    print(f"å°†ä¼ é€’çš„å‚æ•°:")
    print(f"- df_clean ç±»å‹: {type(df_clean)}")
    print(f"- features_clean: {features_clean}")
    print(f"- sensitive_feature: gender")
    print(f"- target_column: loan_approved")

    # 4. åœ¨è°ƒç”¨å‰å†æ¬¡éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
    if df_clean is not None:
        print(f"'gender' åœ¨ df_clean ä¸­: {'gender' in df_clean.columns}")
        for feature in features_clean:
            print(f"'{feature}' åœ¨ df_clean ä¸­: {feature in df_clean.columns}")
        print(f"'loan_approved' åœ¨ df_clean ä¸­: {'loan_approved' in df_clean.columns}")

    # 5. è°ƒç”¨å…¬å¹³æ€§åˆ†æ
    print("\n4. è°ƒç”¨å…¬å¹³æ€§åˆ†æå‡½æ•°...")
    try:
        results = fairlearn_analysis(
            df_clean,
            features=features_clean,
            sensitive_feature='gender',
            target_column='loan_approved'
        )
        print("å…¬å¹³æ€§åˆ†æå®Œæˆ!")
    except Exception as e:
        print(f"å…¬å¹³æ€§åˆ†æå‡ºé”™: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e)}")
        import traceback

        traceback.print_exc()

    if df is not None:
        df_clean, features = data_preprocessing(
            df,
            features=features,
            sensitive_feature='gender',  # æ›¿æ¢ä¸ºä½ çš„æ•æ„Ÿç‰¹å¾åˆ—
            target_column='loan_approved'  # æ›¿æ¢ä¸ºä½ çš„ç›®æ ‡åˆ—
        )

        # å…¬å¹³æ€§åˆ†æ
        results = fairlearn_analysis(
            df_clean,
            sensitive_feature='gender',
            target_column='loan_approved',
            features=features
        )

        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š å‘ç° {len(results['A_test'].unique())} ä¸ªæ•æ„Ÿç‰¹å¾ç»„")
        print(f"âš–ï¸ æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°å®Œæ¯•")

    else:
        print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º...")

        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        np.random.seed(42)
        n_samples = 1000
        example_data = {
            'age': np.random.randint(18, 70, n_samples),
            'income': np.random.normal(50000, 20000, n_samples),
            'credit_score': np.random.normal(650, 100, n_samples),
            'gender': np.random.choice(['Male', 'Female', 'Other'], n_samples, p=[0.5, 0.45, 0.05]),
            'loan_approved': np.random.choice([0, 1], n_samples, p=[0.3, 0.7])
        }
        df_example = pd.DataFrame(example_data)

        print("2. ç¤ºä¾‹æ•°æ®å…¬å¹³æ€§åˆ†æ")
        df_clean, features = data_preprocessing(
            df_example,
            features=features,
            sensitive_feature='gender',
            target_column='loan_approved'

        )

        results = fairlearn_analysis(
            df_clean,
            sensitive_feature='gender',
            target_column='loan_approved',
            features=features
        )