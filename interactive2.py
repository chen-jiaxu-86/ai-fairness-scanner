import pandas as pd
from fairlearn.metrics import(
    demographic_parity_difference ,
    equalized_odds_difference,
    MetricFrame,
    selection_rate,
    count
)
from fairlearn.reductions import GridSearch,DemographicParity
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import  train_test_split
from sklearn.metrics import accuracy_score,precision_score,recall_score
import streamlit as st
import warnings
warnings.filterwarnings("ignore")


def load_data(file_path,file_type='csv'):
    try:
        if file_type.lower() == 'csv':
            df = pd.read_csv(file_path)
        elif file_type.lower() == 'excel':
            df = pd.read_excel(file_path)
        else:
            raise ValueError("æ–‡ä»¶ç±»å‹å¿…é¡»æ˜¯'excel'æˆ–â€˜csv'")
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å½¢çŠ¶: {df.shape}")
        print(f"ğŸ“Š æ•°æ®åˆ—: {list(df.columns)}")
        print("\nğŸ” æ•°æ®å‰5è¡Œ:")
        print(df.head())
        print("\nğŸ“‹ æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(df.info())

        return df
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None


def data_preprocessing(df, features, sensitive_feature, target_column):
    """è°ƒè¯•ç‰ˆé¢„å¤„ç†"""
    try:
        print("=== è°ƒè¯•é¢„å¤„ç†å¼€å§‹ ===")
        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"ç‰¹å¾: {features}")
        print(f"æ•æ„Ÿç‰¹å¾: {sensitive_feature}")
        print(f"ç›®æ ‡å˜é‡: {target_column}")

        # é€‰æ‹©éœ€è¦çš„åˆ—
        required_columns = features + [sensitive_feature, target_column]
        print(f"éœ€è¦çš„åˆ—: {required_columns}")

        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        for col in required_columns:
            if col not in df.columns:
                print(f"âŒ åˆ—ä¸å­˜åœ¨: {col}")
                return None, None

        df_clean = df[required_columns].copy()
        print(f"é€‰æ‹©åˆ—åå½¢çŠ¶: {df_clean.shape}")

        # åˆ é™¤ç¼ºå¤±å€¼
        df_clean = df_clean.dropna()
        print(f"åˆ é™¤ç¼ºå¤±å€¼åå½¢çŠ¶: {df_clean.shape}")

        if len(df_clean) == 0:
            print("è­¦å‘Š: æ¸…ç†åæ²¡æœ‰æ•°æ®äº†")
            return None, None

        print("æ•°æ®ç±»å‹:")
        print(df_clean.dtypes)

        # ç¼–ç åˆ†ç±»å˜é‡
        object_cols = df_clean.select_dtypes(include=['object']).columns
        print(f"éœ€è¦ç¼–ç çš„åˆ—: {list(object_cols)}")

        for col in object_cols:
            print(f"å¤„ç†åˆ—: {col}")
            df_clean[col] = pd.factorize(df_clean[col])[0]

        print("âœ… é¢„å¤„ç†æˆåŠŸ!")
        return df_clean, features

    except Exception as e:
        print(f"âŒ è°ƒè¯•é¢„å¤„ç†é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None, None
def fairlearn_analysis(df,sensitive_feature,target_column,features):
    X = df[features]
    y = df[target_column]
    A = df[sensitive_feature]

    # å°† Xã€yã€A æŒ‰åˆ—ç»„åˆï¼Œç„¶åè¿›è¡Œåˆ†å‰²
    combined = pd.concat([X, y, A], axis=1)
    train, test = train_test_split(combined, test_size=0.3, random_state=42, stratify=y)
    X_train = train[features]
    X_test = test[features]
    y_train = train[target_column]
    y_test = test[target_column]
    A_train = train[sensitive_feature].squeeze(axis=1) if isinstance(train[sensitive_feature], pd.DataFrame) else train[
        sensitive_feature]
    A_test = test[sensitive_feature].squeeze(axis=1) if isinstance(test[sensitive_feature], pd.DataFrame) else test[
        sensitive_feature]

    # ---------------------- æ–°å¢è°ƒè¯•ä¿®å¤ä»£ç å¼€å§‹ ----------------------
    print("ğŸ” è°ƒè¯•ï¼šæ•æ„Ÿç‰¹å¾æ•°æ®ç»“æ„æ£€æŸ¥")
    print(f"æ•æ„Ÿç‰¹å¾åˆ—å½¢çŠ¶: {A_test.shape}")
    print(f"æ•æ„Ÿç‰¹å¾åˆ—ç±»å‹: {type(A_test)}")

    # ç¡®ä¿æ•æ„Ÿç‰¹å¾åˆ—ä¸ºä¸€ç»´ï¼ˆä¿®å¤æ ¸å¿ƒé€»è¾‘ï¼‰
    if len(A_test.shape) > 1:
        print(f"âš ï¸  å‘ç°å¤šç»´æ•æ„Ÿç‰¹å¾ï¼Œè‡ªåŠ¨è½¬ä¸ºä¸€ç»´...")
        # æ–¹å¼1ï¼šé€‚ç”¨äºå¤šç»´æ•°ç»„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        A_test = A_test.iloc[:,0]
        print(f"æ•æ„Ÿç‰¹å¾åˆ—å½¢çŠ¶: {A_test.shape}")
        print(f"æ•æ„Ÿç‰¹å¾åˆ—ç±»å‹: {type(A_test)}")
        # è‹¥æ–¹å¼1å¤±è´¥ï¼Œæ³¨é‡Šä¸Šé¢ä¸€è¡Œï¼Œå¯ç”¨æ–¹å¼2ï¼ˆé€‚ç”¨äºåµŒå¥—åˆ—è¡¨ï¼‰
        # A_test = A_test.explode().reset_index(drop=True)
    # ---------------------- æ–°å¢è°ƒè¯•ä¿®å¤ä»£ç ç»“æŸ ----------------------
    print(f"\nğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    print(f"æ•æ„Ÿç‰¹å¾åˆ†å¸ƒ:")
    print(A_test.value_counts())
    # è®­ç»ƒåŸºç¡€æ¨¡å‹
    print("\nğŸ¤– è®­ç»ƒåŸºç¡€æ¨¡å‹...")
    base_model = RandomForestClassifier(n_estimators=100, random_state=42)
    base_model.fit(X_train, y_train)
    y_pred_base = base_model.predict(X_test)

    print("\n" + "=" * 60)
    print("ğŸ“Š FAIRLEARN å…¬å¹³æ€§åˆ†ææŠ¥å‘Š")
    print("=" * 60)

    # åŸºç¡€æ¨¡å‹æ€§èƒ½
    base_accuracy = accuracy_score(y_test, y_pred_base)
    base_precision = precision_score(y_test, y_pred_base, average='weighted')
    base_recall = recall_score(y_test, y_pred_base, average='weighted')

    print(f"\nğŸ¯ åŸºç¡€æ¨¡å‹æ€§èƒ½:")
    print(f"å‡†ç¡®ç‡: {base_accuracy:.3f}")
    print(f"ç²¾ç¡®ç‡: {base_precision:.3f}")
    print(f"å¬å›ç‡: {base_recall:.3f}")

    # åŸºç¡€æ¨¡å‹æ€§èƒ½
    dp_diff = demographic_parity_difference(y_test,y_pred_base,sensitive_features=A_test)
    eo_diff = equalized_odds_difference(y_test,y_pred_base,sensitive_features=A_test)

    print(f"\nâš–ï¸ å…¬å¹³æ€§æŒ‡æ ‡:")
    print(f"ç»Ÿè®¡å‡ç­‰å·®å¼‚: {dp_diff:.3f} (è¶Šæ¥è¿‘0è¶Šå…¬å¹³)")
    print(f"å‡ç­‰å‡ ç‡å·®å¼‚: {eo_diff:.3f} (è¶Šæ¥è¿‘0è¶Šå…¬å¹³)")

    metrics = {
        'accuracy': accuracy_score,
        'precision': lambda y_true, y_pred: precision_score(y_true, y_pred, average='binary'),
        'recall': lambda y_true, y_pred: recall_score(y_true, y_pred, average='binary'),
        'selection_rate': selection_rate,
        'count': count,
    }

    metric_frame = MetricFrame(
        metrics=metrics,
        y_true=y_test,
        y_pred=y_pred_base,
        sensitive_features=A_test,
    )

    print(f"\nğŸ“‹ æŒ‰ [{sensitive_feature}] åˆ†ç»„çš„è¯¦ç»†æŒ‡æ ‡:")
    print(metric_frame.by_group.round(3))

    # åå·®åˆ†æ
    print(f"\nğŸ“ˆ åå·®åˆ†æ:")
    overall_selection_rate = metric_frame.overall['selection_rate']
    group_selection_rate = metric_frame.by_group['selection_rate']

    for group,rate in group_selection_rate.items():
        bias = rate - overall_selection_rate
        print(f"  {group}: é€‰æ‹©ç‡ = {rate:.3f}, åå·® = {bias:+.3f}")

    return {
        'model': base_model,
        'X_test': X_test,
        'y_test': y_test,
        'A_test': A_test,
        'y_pred_base': y_pred_base,
        'metrics': metric_frame,
        'fairness_metrics': {
            'demographic_parity_diff':dp_diff,
            'equalized_odds_diff':eo_diff,
        },
        'base_accuracy': base_accuracy,
        'base_precision': base_precision,
        'base_recall': base_recall

    }

if __name__ == '__main__':
    print("âš ï¸  æ³¨æ„ï¼šå½“å‰æ¨¡å¼å°†è®­ç»ƒä¸€ä¸ªæ–°çš„éšæœºæ£®æ—æ¨¡å‹ç”¨äºæµ‹è¯•")
    print("AIå®‰å…¨æ€§åˆ†æå·¥å…·")
    print("1.åŠ è½½æ•°æ®æ–‡ä»¶")
    features = []
    use_sample = input("æ˜¯å¦ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼Ÿï¼ˆy/nï¼‰:")
    if use_sample == 'y':
        file_path = "fairlearn_data.csv"  # æˆ– .xlsx
        print(f"é»˜è®¤ä½¿ç”¨æ–‡ä»¶ï¼š{file_path}")
        file_type = "csv"  # æˆ– "excel"
        print(f"ä½¿ç”¨é»˜è®¤æ–‡ä»¶ç±»å‹{file_type}")

        df = load_data(file_path, file_type)
        print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º...")

        features = ['age', 'income', 'credit_score']
        sensitive_feature = 'gender'
        target_column = 'loan_approved'
    else:
        file_path = input("è¯·è¾“å…¥æ•°æ®æ–‡ä»¶è·¯å¾„ï¼š").strip()
        file_type = input("è¯·è¾“å…¥æ–‡ä»¶ç±»å‹ï¼š").strip()

        df = load_data(file_path, file_type)

        print("\n" + "=" * 50)
        print("è¯·é…ç½®åˆ†æå‚æ•°")
        print("=" * 50 )

#       æ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾
        all_columns = df.columns.tolist()
        print(f"æ•°æ®ä¸­æ‰€æœ‰åˆ—ï¼š{all_columns}")
#       é€‰æ‹©ç‰¹å¾åˆ—
        print("\nè¯·é€‰æ‹©ç‰¹å¾åˆ—(ç”¨äºè®­ç»ƒæ¨¡å‹åˆ—)ï¼š")
        for i,col in enumerate(all_columns,1):
            print(f"{i}. {col}")

        feature_choices=input("è¯·è¾“å…¥ç‰¹å¾åˆ—ç¼–ç”¨é€—å·éš”å¼€ï¼Œå¦‚ï¼š1ï¼Œ2ï¼Œ3ï¼‰ï¼š").strip(',')
        features=[all_columns[int(i.strip())-1] for i in feature_choices if i.strip().isdigit()]

#       é€‰æ‹©æ•æ„Ÿç‰¹å¾
        print(f"\nè¯·è¾“å…¥æ•æ„Ÿç‰¹å¾åˆ— (ç”¨äºå…¬å¹³æ€§åˆ†æçš„åˆ—):")
        for i, col in enumerate(all_columns, 1):
            print(f"  {i}. {col}")
        sensitive_idx = input("è¯·è¾“å…¥1ä¸ªæ•æ„Ÿç‰¹å¾åˆ—çš„ç¼–å·: ").strip()
        sensitive_feature = all_columns[int(sensitive_idx) - 1] if sensitive_idx.isdigit() else None

        # é€‰æ‹©ç›®æ ‡å˜é‡
        print(f"\nğŸ¯ è¯·é€‰æ‹©ç›®æ ‡å˜é‡åˆ—:")
        for i, col in enumerate(all_columns, 1):
            print(f"  {i}. {col}")
        target_idx = input("è¯·è¾“å…¥1ä¸ªç›®æ ‡å˜é‡åˆ—çš„ç¼–å·: ").strip()
        target_column = all_columns[int(target_idx) - 1] if target_idx.isdigit() else None

        print(f"\nğŸ” è°ƒè¯•ä¿¡æ¯:")
        print(f"features: {features} (é•¿åº¦: {len(features)})")
        print(f"sensitive_feature: {sensitive_feature}")
        print(f"target_column: {target_column}")

        # éªŒè¯é€‰æ‹©
        if not features or not sensitive_feature or not target_column:
            print("âŒ å‚æ•°é€‰æ‹©ä¸å®Œæ•´ï¼Œè¯·é‡æ–°è¿è¡Œï¼")
            print(f"  ç¼ºå¤±çš„ç‰¹å¾: {'features' if not features else ''}")
            print(f"  ç¼ºå¤±çš„æ•æ„Ÿç‰¹å¾: {'sensitive_feature' if not sensitive_feature else ''}")
            print(f"  ç¼ºå¤±çš„ç›®æ ‡å˜é‡: {'target_column' if not target_column else ''}")
            exit()

    print(f"\nâœ… åˆ†æé…ç½®ç¡®è®¤:")
    print(f"ç‰¹å¾åˆ—: {features}")
    print(f"æ•æ„Ÿç‰¹å¾: {sensitive_feature}")
    print(f"ç›®æ ‡å˜é‡: {target_column}")



    df_clean, features_clean = data_preprocessing(
        df,
        features=features,
        sensitive_feature=sensitive_feature,  # æ›¿æ¢ä¸ºä½ çš„æ•æ„Ÿç‰¹å¾åˆ—
        target_column=target_column  # æ›¿æ¢ä¸ºä½ çš„ç›®æ ‡åˆ—
     )


    # å…¬å¹³æ€§åˆ†æ
    if df_clean is not None:
        results = fairlearn_analysis(
            df_clean,
            sensitive_feature=sensitive_feature,
            target_column=target_column,
            features=features_clean
        )
        if results is not None:
            print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
            print(f"ğŸ“Š å‘ç° {len(results['A_test'].unique())} ä¸ªæ•æ„Ÿç‰¹å¾ç»„")
            print(f"âš–ï¸ æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°å®Œæ¯•")
        else:
            print("å…¬å¹³æ€§åˆ†æå¤±è´¥")
    else:
        print("æ•°æ®å¤„ç†å¤±è´¥")

